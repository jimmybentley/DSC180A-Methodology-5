James Bentley, jbentley@ucsd.edu

B07, Lindsey Kostas

1) The applications of graph ML on FPGA and ASIC design was the most interesting part. Applying something I know to a new domain.

2) Finding representative batches of subgraphs for optimal batch processing to reduce training time and compute resources used.

3) We currently are considering partition and centrality algorithms for creating representations. I am considering trying out contrastive learning and curriculum learning.

4) We could try training on multiple gpus to check out how our model scales on multiple gpu partitions.
